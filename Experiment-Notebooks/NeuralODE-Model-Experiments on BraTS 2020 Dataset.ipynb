{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "843caf09",
   "metadata": {},
   "source": [
    "# NeuralODE for Brain Tumor Segmentation on BraTS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53e7a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc0cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class bratsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    __init__ needs a rootPath\n",
    "    from there it assumes there are two folders numtrain and numlabels containing numpy files\n",
    "    \"\"\"\n",
    "    def __init__(self, rootPath, PATH_SIZE):\n",
    "        self.train = []\n",
    "        self.labels = []\n",
    "        \n",
    "        pathTrain = os.path.join(rootPath, 'num'+ PATH_SIZE + 'train')\n",
    "        imgPaths = os.listdir(pathTrain)\n",
    "        for path in imgPaths:\n",
    "            if path.endswith('.npy'):\n",
    "                self.train.append(os.path.join(pathTrain, path))\n",
    "        \n",
    "        pathLabels = os.path.join(rootPath, 'num' + PATH_SIZE + 'labels')\n",
    "        imgPaths = os.listdir(pathLabels)\n",
    "        for path in imgPaths:\n",
    "            if path.endswith('.npy'):\n",
    "                self.labels.append(os.path.join(pathLabels, path))\n",
    "        \n",
    "    def __len__(self):\n",
    "        assert len(self.train) == len(self.labels)\n",
    "        return len(self.train)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        x = np.load(self.train[idx])\n",
    "        x = torch.from_numpy(x)\n",
    "        x = x.float()\n",
    "        \n",
    "        y = np.load(self.labels[idx])\n",
    "        y = torch.from_numpy(y)\n",
    "        y = y.float()\n",
    "        \n",
    "        return x,y\n",
    "\n",
    "\n",
    "class brats3dDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Needs a rootPath.\n",
    "    Expects to find 'source' and 'target' folders.\n",
    "    Expects to deal with preprocessed numpy files.\n",
    "    \"\"\"\n",
    "    def __init__(self, rootPath):\n",
    "        self.source = []\n",
    "        self.target = []\n",
    "        # perhaps a pandas Series would be better than an array?\n",
    "        \n",
    "        pathSource = os.path.join(rootPath, 'source')\n",
    "        imgPaths = os.listdir(pathSource)\n",
    "        for path in imgPaths:\n",
    "            if path.endswith('.npy'):\n",
    "                self.source.append(os.path.join(pathSource, path))\n",
    "        \n",
    "        pathTarget = os.path.join(rootPath, 'target')\n",
    "        imgPaths = os.listdir(pathTarget)\n",
    "        for path in imgPaths:\n",
    "            if path.endswith('.npy'):\n",
    "                self.target.append(os.path.join(pathTarget, path))\n",
    "        \n",
    "    def __len__(self):\n",
    "        assert len(self.source) == len(self.target)\n",
    "        return len(self.source)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        x = np.load(self.source[idx])\n",
    "        x = torch.from_numpy(x)\n",
    "        x = x.float()\n",
    "        \n",
    "        y = np.load(self.target[idx])\n",
    "        y = torch.from_numpy(y)\n",
    "        y = y.float()\n",
    "        \n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2abe40",
   "metadata": {},
   "source": [
    "# Preprocessing BraTS Dataset (preprocess.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ab88ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pdb\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "IMG_ROOT = './Task01_BrainTumor/imagesTr'\n",
    "IMG_PATH = './Task01_BrainTumor/imagesTr/BRATS_148.nii.gz'\n",
    "IMG_OUTPUT_ROOT = './train/image_T1'\n",
    "\n",
    "LABEL_ROOT = './Task01_BrainTumor/labelsTr'\n",
    "IABEL_PATH = './Task01_BrainTumor/labelsTr/BRATS_148.nii.gz'\n",
    "LABEL_OUTPUT_ROOT = './train/label'\n",
    "\n",
    "L0 = 0      # Background\n",
    "L1 = 50     # Necrotic and Non-enhancing Tumor\n",
    "L2 = 100    # Edema\n",
    "L3 = 150    # Enhancing Tumor\n",
    "\n",
    "# MRI Image channels Description\n",
    "# ch0: FLAIR / ch1: T1 / ch2: T1c/ ch3: T2\n",
    "# cf) In this project, we use FLAIR and T1c MRI dataset\n",
    "# \n",
    "# Data Load Example\n",
    "#img = nib.load(IMG_PATH)\n",
    "#img = (img.get_fdata())[:,:,:,3]                # img shape = (240,240,155)\n",
    "\n",
    "\n",
    "# MRI Label Channels Description\n",
    "# 0: Background         / 1: Necrotic and non-enhancing tumor (paper, 1+3)\n",
    "# 2: edema (paper, 2)   / 3: Enhancing tumor (paper, 4)\n",
    "# \n",
    "# <Input>           <Prediction>\n",
    "# FLAIR             Complete(1,2,3)\n",
    "# FLAIR             Core(1,3)\n",
    "# T1c               Enhancing(3)\n",
    "#\n",
    "# Data Load Example\n",
    "# label = nib.load(LABEL_PATH)\n",
    "# label = (label.get_fdata()).astype(np.uint16)   # label shape = (240,240,155)\n",
    "\n",
    "\n",
    "def nii2jpg_img(img_path, output_root):\n",
    "    img_name = (img_path.split('/')[-1]).split('.')[0]\n",
    "    output_path = os.path.join(output_root, img_name)\n",
    "    try:\n",
    "        os.makedirs(output_root)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        os.makedirs(output_path)\n",
    "    except:\n",
    "        pass\n",
    "    img = nib.load(img_path)\n",
    "    img = (img.get_fdata())[:,:,:,1]\n",
    "    img = (img/img.max())*255\n",
    "    img = img.astype(np.uint8)\n",
    "\n",
    "    for i in range(img.shape[2]):\n",
    "        filename = os.path.join(output_path, img_name+'_'+str(i)+'.jpg')\n",
    "        gray_img = img[:,:,i]\n",
    "        #color_img = np.expand_dims(gray_img, 3)\n",
    "        #color_img = np.concatenate([color_img, color_img, color_img], 2)\n",
    "\n",
    "        # COLOR LABELING\n",
    "        #c255 = np.expand_dims(np.ones(gray_img.shape)*255, 3)\n",
    "        #c0 = np.expand_dims(np.zeros(gray_img.shape), 3)\n",
    "        #color = np.concatenate([c0,c0,c255], 2)\n",
    "        #color_img = color_img.astype(np.float32) + color\n",
    "        #color_img = (color_img / color_img.max()) *255\n",
    "\n",
    "        cv2.imwrite(filename, gray_img)\n",
    "\n",
    "\n",
    "def nii2jpg_label(img_path, output_root):\n",
    "    img_name = (img_path.split('/')[-1]).split('.')[0]\n",
    "    output_path = os.path.join(output_root, img_name)\n",
    "    try:\n",
    "        os.mkdir(output_root)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        os.mkdir(output_path)\n",
    "    except:\n",
    "        pass\n",
    "    img = nib.load(img_path)\n",
    "    img = (img.get_fdata())[:,:,:]\n",
    "    pdb.set_trace()\n",
    "    img = img*50\n",
    "    img = img.astype(np.uint8)\n",
    "\n",
    "    for i in range(img.shape[2]):\n",
    "        filename = os.path.join(output_path, img_name+'_'+str(i)+'.jpg')\n",
    "        gray_img = img[:,:,i]\n",
    "        #color_img = np.expand_dims(gray_img, 3)\n",
    "        #color_img = np.concatenate([color_img, color_img, color_img], 2)\n",
    "\n",
    "        # COLOR LABELING\n",
    "        #c255 = np.expand_dims(np.ones(gray_img.shape)*255, 3)\n",
    "        #c0 = np.expand_dims(np.zeros(gray_img.shape), 3)\n",
    "        #color = np.concatenate([c0,c0,c255], 2)\n",
    "        #color_img = color_img.astype(np.float32) + color\n",
    "        #color_img = (color_img / color_img.max()) *255\n",
    "\n",
    "        cv2.imwrite(filename, gray_img)\n",
    "\n",
    "\n",
    "for path in os.listdir(IMG_ROOT):\n",
    "    print(path)\n",
    "    if path[0] == '.':\n",
    "        continue\n",
    "    nii2jpg_img(os.path.join(IMG_ROOT,path), IMG_OUTPUT_ROOT)\n",
    "'''\n",
    "for path in os.listdir(LABEL_ROOT):\n",
    "    print(path)\n",
    "    if path[0] == '.':\n",
    "        continue\n",
    "    nii2jpg_label(os.path.join(LABEL_ROOT,path), LABEL_OUTPUT_ROOT)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bafcdb",
   "metadata": {},
   "source": [
    "# Config.py file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbac976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Device Init\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Model output shape Init\n",
    "class_num = 2\n",
    "\n",
    "\n",
    "# Data Handling Parameters\n",
    "complete_threshold = 0.05\n",
    "complete_rate = 0.66\n",
    "\n",
    "core_threshold = 0.05\n",
    "core_rate = 0.66\n",
    "\n",
    "enhancing_threshold = 0.02\n",
    "enhancing_rate = 0.7\n",
    "\n",
    "# Data Augmentation Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d047452",
   "metadata": {},
   "source": [
    "# Utils.py script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228cecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import logging.handlers\n",
    "import pydensecrf.densecrf as dcrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da105401",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Checkpoint:\n",
    "    def __init__(self, model, optimizer=None, epoch=0, best_score=1):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.epoch = epoch\n",
    "        self.best_score = best_score\n",
    "\n",
    "    def load(self, path):\n",
    "        checkpoint = torch.load(path)\n",
    "        self.model.load_state_dict(checkpoint[\"model_state\"])\n",
    "        self.epoch = checkpoint[\"epoch\"]\n",
    "        self.best_score = checkpoint[\"best_score\"]\n",
    "        if self.optimizer:\n",
    "            self.optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "            for state in self.optimizer.state.values():\n",
    "                  for k, v in state.items():\n",
    "                           if torch.is_tensor(v):\n",
    "                                    state[k] = v.cuda()\n",
    "\n",
    "    def save(self, path):\n",
    "        state_dict = self.model.module.state_dict()\n",
    "        torch.save({\"model_state\": state_dict,\n",
    "                    \"optimizer_state\": self.optimizer.state_dict(),\n",
    "                    \"epoch\": self.epoch,\n",
    "                    \"best_score\": self.best_score}, path)\n",
    "\n",
    "\n",
    "def progress_bar(current, total, msg=None):\n",
    "    ''' Source Code from 'kuangliu/pytorch-cifar'\n",
    "        (https://github.com/kuangliu/pytorch-cifar/blob/master/utils.py)\n",
    "    '''\n",
    "    global last_time, begin_time\n",
    "    if current == 0:\n",
    "        begin_time = time.time()  # Reset for new bar.\n",
    "\n",
    "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
    "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
    "\n",
    "    sys.stdout.write(' [')\n",
    "    for i in range(cur_len):\n",
    "        sys.stdout.write('=')\n",
    "    sys.stdout.write('>')\n",
    "    for i in range(rest_len):\n",
    "        sys.stdout.write('.')\n",
    "    sys.stdout.write(']')\n",
    "\n",
    "    cur_time = time.time()\n",
    "    step_time = cur_time - last_time\n",
    "    last_time = cur_time\n",
    "    tot_time = cur_time - begin_time\n",
    "\n",
    "    L = []\n",
    "    L.append('  Step: %s' % format_time(step_time))\n",
    "    L.append(' | Tot: %s' % format_time(tot_time))\n",
    "    if msg:\n",
    "        L.append(' | ' + msg)\n",
    "\n",
    "    msg = ''.join(L)\n",
    "    sys.stdout.write(msg)\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
    "        sys.stdout.write(' ')\n",
    "\n",
    "    # Go back to the center of the bar.\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
    "        sys.stdout.write('\\b')\n",
    "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
    "\n",
    "    if current < total-1:\n",
    "        sys.stdout.write('\\r')\n",
    "    else:\n",
    "        sys.stdout.write('\\n')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def format_time(seconds):\n",
    "    ''' Source Code from 'kuangliu/pytorch-cifar'\n",
    "        (https://github.com/kuangliu/pytorch-cifar/blob/master/utils.py)\n",
    "    '''\n",
    "    days = int(seconds / 3600/24)\n",
    "    seconds = seconds - days*3600*24\n",
    "    hours = int(seconds / 3600)\n",
    "    seconds = seconds - hours*3600\n",
    "    minutes = int(seconds / 60)\n",
    "    seconds = seconds - minutes*60\n",
    "    secondsf = int(seconds)\n",
    "    seconds = seconds - secondsf\n",
    "    millis = int(seconds*1000)\n",
    "\n",
    "    f = ''\n",
    "    i = 1\n",
    "    if days > 0:\n",
    "        f += str(days) + 'D'\n",
    "        i += 1\n",
    "    if hours > 0 and i <= 2:\n",
    "        f += str(hours) + 'h'\n",
    "        i += 1\n",
    "    if minutes > 0 and i <= 2:\n",
    "        f += str(minutes) + 'm'\n",
    "        i += 1\n",
    "    if secondsf > 0 and i <= 2:\n",
    "        f += str(secondsf) + 's'\n",
    "        i += 1\n",
    "    if millis > 0 and i <= 2:\n",
    "        f += str(millis) + 'ms'\n",
    "        i += 1\n",
    "    if f == '':\n",
    "        f = '0ms'\n",
    "    return f\n",
    "\n",
    "\n",
    "def get_logger(level=\"DEBUG\", file_level=\"DEBUG\"):\n",
    "    logger = logging.getLogger(None)\n",
    "    logger.setLevel(level)\n",
    "    fomatter = logging.Formatter(\n",
    "            '%(asctime)s  [%(levelname)s]  %(message)s  (%(filename)s:  %(lineno)s)')\n",
    "    fileHandler = logging.handlers.TimedRotatingFileHandler(\n",
    "            'result.log', when='d', encoding='utf-8')\n",
    "    fileHandler.setLevel(file_level)\n",
    "    fileHandler.setFormatter(fomatter)\n",
    "    logger.addHandler(fileHandler)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1df37a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydensecrf.utils import compute_unary, create_pairwise_bilateral,\\\n",
    "         create_pairwise_gaussian, softmax_to_unary, unary_from_softmax\n",
    "\n",
    "_, term_width = os.popen('stty size', 'r').read().split()\n",
    "term_width = int(term_width)\n",
    "\n",
    "TOTAL_BAR_LENGTH = 65.\n",
    "last_time = time.time()\n",
    "begin_time = last_time\n",
    "\n",
    "\n",
    "def dice_coef(preds, targets, backprop=True):\n",
    "    smooth = 1.0\n",
    "    class_num = 2\n",
    "    if backprop:\n",
    "        for i in range(class_num):\n",
    "            pred = preds[:,i,:,:]\n",
    "            target = targets[:,i,:,:]\n",
    "            intersection = (pred * target).sum()\n",
    "            loss_ = 1 - ((2.0 * intersection + smooth) / (pred.sum() + target.sum() + smooth))\n",
    "            if i == 0:\n",
    "                loss = loss_\n",
    "            else:\n",
    "                loss = loss + loss_\n",
    "        loss = loss/class_num\n",
    "        return loss\n",
    "    else:\n",
    "        # Need to generalize\n",
    "        targets = np.array(targets.argmax(1))\n",
    "        if len(preds.shape) > 3:\n",
    "            preds = np.array(preds).argmax(1)\n",
    "        for i in range(class_num):\n",
    "            pred = (preds==i).astype(np.uint8)\n",
    "            target= (targets==i).astype(np.uint8)\n",
    "            intersection = (pred * target).sum()\n",
    "            loss_ = 1 - ((2.0 * intersection + smooth) / (pred.sum() + target.sum() + smooth))\n",
    "            if i == 0:\n",
    "                loss = loss_\n",
    "            else:\n",
    "                loss = loss + loss_\n",
    "        loss = loss/class_num\n",
    "        return loss\n",
    "\n",
    "\n",
    "def get_crf_img(inputs, outputs):\n",
    "    for i in range(outputs.shape[0]):\n",
    "        img = inputs[i]\n",
    "        softmax_prob = outputs[i]\n",
    "        unary = unary_from_softmax(softmax_prob)\n",
    "        unary = np.ascontiguousarray(unary)\n",
    "        d = dcrf.DenseCRF(img.shape[0] * img.shape[1], 2)\n",
    "        d.setUnaryEnergy(unary)\n",
    "        feats = create_pairwise_gaussian(sdims=(10,10), shape=img.shape[:2])\n",
    "        d.addPairwiseEnergy(feats, compat=3, kernel=dcrf.DIAG_KERNEL,\n",
    "                            normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "        feats = create_pairwise_bilateral(sdims=(50,50), schan=(20,20,20),\n",
    "                                          img=img, chdim=2)\n",
    "        d.addPairwiseEnergy(feats, compat=10, kernel=dcrf.DIAG_KERNEL,\n",
    "                            normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "        Q = d.inference(5)\n",
    "        res = np.argmax(Q, axis=0).reshape((img.shape[0], img.shape[1]))\n",
    "        if i == 0:\n",
    "            crf = np.expand_dims(res,axis=0)\n",
    "        else:\n",
    "            res = np.expand_dims(res,axis=0)\n",
    "            crf = np.concatenate((crf,res),axis=0)\n",
    "    return crf\n",
    "\n",
    "\n",
    "def erode_dilate(outputs, kernel_size=7):\n",
    "    kernel = np.ones((kernel_size,kernel_size),np.uint8)\n",
    "    outputs = outputs.astype(np.uint8)\n",
    "    for i in range(outputs.shape[0]):\n",
    "        img = outputs[i]\n",
    "        img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "        img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "        outputs[i] = img\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def post_process(args, inputs, outputs, input_path=None,\n",
    "                 crf_flag=True, erode_dilate_flag=True,\n",
    "                 save=True, overlap=True):\n",
    "    inputs = (np.array(inputs.squeeze()).astype(np.float32)) * 255\n",
    "    inputs = np.expand_dims(inputs, axis=3)\n",
    "    inputs = np.concatenate((inputs,inputs,inputs), axis=3)\n",
    "    outputs = np.array(outputs)\n",
    "\n",
    "    # Conditional Random Field\n",
    "    if crf_flag:\n",
    "        outputs = get_crf_img(inputs, outputs)\n",
    "    else:\n",
    "        outputs = outputs.argmax(1)\n",
    "\n",
    "    # Erosion and Dilation\n",
    "    if erode_dilate_flag:\n",
    "        outputs = erode_dilate(outputs, kernel_size=7)\n",
    "    if save == False:\n",
    "        return outputs\n",
    "\n",
    "    outputs = outputs*255\n",
    "    for i in range(outputs.shape[0]):\n",
    "        path = input_path[i].split('/')\n",
    "        output_folder = os.path.join(args.output_root, path[-2])\n",
    "        try:\n",
    "            os.mkdir(output_folder)\n",
    "        except:\n",
    "            pass\n",
    "        output_path = os.path.join(output_folder, path[-1])\n",
    "        if overlap:\n",
    "            img = outputs[i]\n",
    "            img = np.expand_dims(img, axis=2)\n",
    "            zeros = np.zeros(img.shape)\n",
    "            img = np.concatenate((zeros,zeros,img), axis=2)\n",
    "            img = np.array(img).astype(np.float32)\n",
    "            img = inputs[i] + img\n",
    "            if img.max() > 0:\n",
    "                img = (img/img.max())*255\n",
    "            else:\n",
    "                img = (img/1) * 255\n",
    "            cv2.imwrite(output_path, img)\n",
    "        else:\n",
    "            img = outputs[i]\n",
    "            cv2.imwrite(output_path, img)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d74b989",
   "metadata": {},
   "source": [
    "# UNet Model architecture code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c35260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "\n",
    "def conv3x3(in_c, out_c, kernel_size=3, stride=1, padding=1,\n",
    "            bias=True, useBN=False, drop_rate=0):\n",
    "    if useBN:\n",
    "        return nn.Sequential(\n",
    "                nn.ReflectionPad2d(padding),\n",
    "                nn.Conv2d(in_c, out_c, kernel_size, stride, padding=0, bias=bias),\n",
    "                nn.BatchNorm2d(out_c),\n",
    "                nn.Dropout2d(p=drop_rate),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.ReflectionPad2d(padding),\n",
    "                nn.Conv2d(out_c, out_c, kernel_size, stride, padding=0, bias=bias),\n",
    "                nn.BatchNorm2d(out_c),\n",
    "                nn.Dropout2d(p=drop_rate),\n",
    "                nn.ReLU(inplace=True))\n",
    "    else:\n",
    "        return nn.Sequential(\n",
    "                nn.ReflectionPad2d(padding),\n",
    "                nn.Conv2d(in_c, out_c, kernel_size, stride, padding=0, bias=bias),\n",
    "                nn.Dropout2d(p=drop_rate),\n",
    "                nn.ReLU(),\n",
    "                nn.ReflectionPad2d(padding),\n",
    "                nn.Conv2d(out_c, out_c, kernel_size, stride, padding=0, bias=bias),\n",
    "                nn.Dropout2d(p=drop_rate),\n",
    "                nn.ReLU())\n",
    "\n",
    "\n",
    "def upsample(in_c, out_c, bias=True, drop_rate=0):\n",
    "\treturn nn.Sequential(\n",
    "        #nn.ReflectionPad2d(1),\n",
    "\t\tnn.ConvTranspose2d(in_c, out_c, 4, 2, 1, bias=bias),\n",
    "        nn.Dropout2d(p=drop_rate),\n",
    "        nn.ReLU())\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channel=1, class_num=2, useBN=False, drop_rate=0):\n",
    "        super(UNet, self).__init__()\n",
    "        self.output_dim = class_num\n",
    "        self.drop_rate = drop_rate\n",
    "        self.conv1 = conv3x3(in_channel, 64, useBN=useBN, drop_rate=self.drop_rate)\n",
    "        self.conv2 = conv3x3(64, 128, useBN=useBN, drop_rate=self.drop_rate)\n",
    "        self.conv3 = conv3x3(128, 256, useBN=useBN, drop_rate=self.drop_rate)\n",
    "        self.conv4 = conv3x3(256, 512, useBN=useBN, drop_rate=self.drop_rate)\n",
    "        self.conv5 = conv3x3(512, 1024, useBN=useBN, drop_rate=self.drop_rate)\n",
    "\n",
    "        self.conv4m = conv3x3(1024, 512, useBN=useBN, drop_rate=self.drop_rate)\n",
    "        self.conv3m = conv3x3(512, 256, useBN=useBN, drop_rate=self.drop_rate)\n",
    "        self.conv2m = conv3x3(256, 128, useBN=useBN, drop_rate=self.drop_rate)\n",
    "        self.conv1m = conv3x3(128, 64, useBN=useBN, drop_rate=self.drop_rate)\n",
    "\n",
    "        self.conv0  = nn.Sequential(nn.ReflectionPad2d(1),\n",
    "                                    nn.Conv2d(64, self.output_dim, 3, 1, 0),\n",
    "                                    nn.Dropout2d(p=self.drop_rate),\n",
    "                                    nn.ReLU())\n",
    "        self.max_pool = nn.MaxPool2d(2)\n",
    "\n",
    "        self.upsample54 = upsample(1024, 512, drop_rate=self.drop_rate)\n",
    "        self.upsample43 = upsample(512, 256, drop_rate=self.drop_rate)\n",
    "        self.upsample32 = upsample(256, 128, drop_rate=self.drop_rate)\n",
    "        self.upsample21 = upsample(128, 64, drop_rate=self.drop_rate)\n",
    "\n",
    "\t\t## weight initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "                nn.init.normal_(m.weight.data, mean=0, std=0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output1 = self.conv1(x)\n",
    "        output2 = self.conv2(self.max_pool(output1))\n",
    "        output3 = self.conv3(self.max_pool(output2))\n",
    "        output4 = self.conv4(self.max_pool(output3))\n",
    "        output5 = self.conv5(self.max_pool(output4))\n",
    "\n",
    "        conv5m_out = torch.cat((self.upsample54(output5), output4), 1)\n",
    "        conv4m_out = self.conv4m(conv5m_out)\n",
    "        conv4m_out = torch.cat((self.upsample43(output4), output3), 1)\n",
    "        conv3m_out = self.conv3m(conv4m_out)\n",
    "\n",
    "        conv3m_out = torch.cat((self.upsample32(output3), output2), 1)\n",
    "        conv2m_out = self.conv2m(conv3m_out)\n",
    "\n",
    "        conv2m_out = torch.cat((self.upsample21(output2), output1), 1)\n",
    "        conv1m_out = self.conv1m(conv2m_out)\n",
    "\n",
    "        final = self.conv0(conv1m_out)\n",
    "        final = softmax(final, dim=1)\n",
    "        return final\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = UNet(class_num=2)\n",
    "    y = net(torch.randn(3,1,240,240))\n",
    "    print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfe2405",
   "metadata": {},
   "source": [
    "# Trainer Code (train.py) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0c286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import pdb\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from config import *\n",
    "from dataset import *\n",
    "from models import *\n",
    "from utils import *\n",
    "\n",
    "\n",
    "def train(args):\n",
    "\n",
    "    # Variables and logger Init\n",
    "    device = config.device\n",
    "    cudnn.benchmark = True\n",
    "    get_logger()\n",
    "\n",
    "    # Data Load\n",
    "    trainloader = data_loader(args, mode='train')\n",
    "    validloader = data_loader(args, mode='valid')\n",
    "\n",
    "    # Model Load\n",
    "    net, optimizer, best_score, start_epoch =\\\n",
    "        load_model(args, class_num=config.class_num, mode='train')\n",
    "    log_msg = '\\n'.join(['%s Train Start'%(args.model)])\n",
    "    logging.info(log_msg)\n",
    "\n",
    "    for epoch in range(start_epoch, start_epoch+args.epochs):\n",
    "\n",
    "        # Train Model\n",
    "        print('\\n\\n\\nEpoch: {}\\n<Train>'.format(epoch))\n",
    "        net.train(True)\n",
    "        loss = 0\n",
    "        lr = args.lr * (0.5 ** (epoch // 4))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "        torch.set_grad_enabled(True)\n",
    "        for idx, (inputs, targets, paths) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            if type(outputs) == tuple:\n",
    "                outputs = outputs[0]\n",
    "            batch_loss = dice_coef(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            loss += float(batch_loss)\n",
    "            progress_bar(idx, len(trainloader), 'Loss: %.5f, Dice-Coef: %.5f'\n",
    "                         %((loss/(idx+1)), (1-(loss/(idx+1)))))\n",
    "        log_msg = '\\n'.join(['Epoch: %d  Loss: %.5f,  Dice-Coef:  %.5f'\\\n",
    "                         %(epoch, loss/(idx+1), 1-(loss/(idx+1)))])\n",
    "        logging.info(log_msg)\n",
    "\n",
    "        # Validate Model\n",
    "        print('\\n\\n<Validation>')\n",
    "        net.eval()\n",
    "        for module in net.module.modules():\n",
    "            if isinstance(module, torch.nn.modules.Dropout2d):\n",
    "                module.train(True)\n",
    "            elif isinstance(module, torch.nn.modules.Dropout):\n",
    "                module.train(True)\n",
    "            else:\n",
    "                pass\n",
    "        loss = 0\n",
    "        torch.set_grad_enabled(False)\n",
    "        for idx, (inputs, targets, paths) in enumerate(validloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            if type(outputs) == tuple:\n",
    "                outputs = outputs[0]\n",
    "            #outputs = post_process(args, inputs, outputs, save=False)\n",
    "            batch_loss = dice_coef(outputs, targets, backprop=False)\n",
    "            loss += float(batch_loss)\n",
    "            progress_bar(idx, len(validloader), 'Loss: %.5f, Dice-Coef: %.5f'\n",
    "                         %((loss/(idx+1)), (1-(loss/(idx+1)))))\n",
    "        log_msg = '\\n'.join(['Epoch: %d  Loss: %.5f,  Dice-Coef:  %.5f'\n",
    "                        %(epoch, loss/(idx+1), 1-(loss/(idx+1)))])\n",
    "        logging.info(log_msg)\n",
    "\n",
    "        # Save Model\n",
    "        loss /= (idx+1)\n",
    "        score = 1 - loss\n",
    "        if score > best_score:\n",
    "            checkpoint = Checkpoint(net, optimizer, epoch, score)\n",
    "            checkpoint.save(os.path.join(args.ckpt_root, args.model+'.tar'))\n",
    "            best_score = score\n",
    "            print(\"Saving...\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=__doc__)\n",
    "    parser.add_argument(\"--resume\", type=bool, default=False,\n",
    "                        help=\"Model Trianing resume.\")\n",
    "    parser.add_argument(\"--model\", type=str, default='pspnet_res50',\n",
    "                        help=\"Model Name (unet, pspnet_squeeze, pspnet_res50,\\\n",
    "                        pspnet_res34, pspnet_res50, deeplab)\")\n",
    "    parser.add_argument(\"--in_channel\", type=int, default=1,\n",
    "                        help=\"A number of images to use for input\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=80,\n",
    "                        help=\"The batch size to load the data\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=30,\n",
    "                        help=\"The training epochs to run.\")\n",
    "    parser.add_argument(\"--drop_rate\", type=float, default=0.1,\n",
    "                        help=\"Drop-out Rate\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.001,\n",
    "                        help=\"Learning rate to use in training\")\n",
    "    parser.add_argument(\"--data\", type=str, default=\"complete\",\n",
    "                        help=\"Label data type.\")\n",
    "    parser.add_argument(\"--img_root\", type=str, default=\"../../data/train/image_FLAIR\",\n",
    "                        help=\"The directory containing the training image dataset.\")\n",
    "    parser.add_argument(\"--label_root\", type=str, default=\"../../data/train/label\",\n",
    "                        help=\"The directory containing the training label datgaset\")\n",
    "    parser.add_argument(\"--output_root\", type=str, default=\"./output/prediction\",\n",
    "                        help=\"The directory containing the result predictions\")\n",
    "    parser.add_argument(\"--ckpt_root\", type=str, default=\"./checkpoint\",\n",
    "                        help=\"The directory containing the checkpoint files\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2100f7e6",
   "metadata": {},
   "source": [
    "# Testing (test.py) Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b8583d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85f043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import argparse\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from config import *\n",
    "from dataset import *\n",
    "from models import *\n",
    "from utils import *\n",
    "\n",
    "\n",
    "def test(args):\n",
    "\n",
    "    # Device Init\n",
    "    device = config.device\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    # Data Load\n",
    "    testloader = data_loader(args, mode='test')\n",
    "\n",
    "    # Model Load\n",
    "    net, _, _, _ = load_model(args, class_num=config.class_num, mode='test')\n",
    "\n",
    "    net.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "    for idx, (inputs, paths) in enumerate(testloader):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = net(inputs)\n",
    "        if type(outputs) == tuple:\n",
    "            outputs = outputs[0]\n",
    "        post_process(args, inputs, outputs, paths)\n",
    "        print(idx)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=__doc__)\n",
    "    parser.add_argument(\"--model\", type=str, default='pspnet', # Need to be fixed\n",
    "                        help=\"Model Name\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=155, # Need to be fixed\n",
    "                        help=\"The batch size to load the data\")\n",
    "    parser.add_argument(\"--data\", type=str, default=\"complete\",\n",
    "                        help=\"Label data type.\")\n",
    "    parser.add_argument(\"--img_root\", type=str, default=\"../data/train/image_FLAIR\",\n",
    "                        help=\"The directory containing the training image dataset.\")\n",
    "    parser.add_argument(\"--output_root\", type=str, default=\"./output/prediction\",\n",
    "                        help=\"The directory containing the results.\")\n",
    "    parser.add_argument(\"--ckpt_root\", type=str, default=\"./checkpoint\",\n",
    "                        help=\"The directory containing the trained model checkpoint\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    test(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
